# PROPOSITION

### Script for filmed section:

WELCOME TO THE FUTURE!

Hi, my name is Joe. Founder of OMEN Systems and creator of OMEN1 - A personal healthcare assistant powered by Artificial Intelligence. Ever since OMEN1 hit the market last year (2030 by the way) people have been asking what's next for the innovators at OMEN Systems!&#x20;

WELL!&#x20;

Let me introduce ControlForge! An innovative method of interfacing with AI design tools that anyone, even your mother, can understand!&#x20;

ControlForge takes many of the obtuse and complex features of Ai art and design and gives them a  physical form.&#x20;

In 2022, AI art really hit the mainstream with things like Midjourney and Stable Diffusion. These tool relied on:

Text Prompting and prompt weighting

Checkpoint models and LoRA's

Image uploading

Samplers and Classifer Free Guidence

And something called 'ControlNET'&#x20;

ControlForge aims to condense all of these functions into something intuitive to use, physical and most importantly a system doesn't limit the creative output of AI design.

The first model is aimed at character designers and their AI workflow, but the technology can be applied to any area of product design.&#x20;

But how does it work?&#x20;

ControlForge is largely based on ControlNET. A feature of stable diffusion mentioned before. You first put a 'base model' - in this case OMEN1 - into the unit. This is roughly the equivalent to uploading an image into Stable Diffusion.&#x20;

But instead of typing some long and nonsense text prompt and prompt weighting. ControlForge gets its additional information from placing other figures into the two weighting units.&#x20;

The ControlForge AI model will use these two weighting units and the figures within in to get pose, colour and detail information.&#x20;

The how much 'weight' is taken from these figures can be controlled by physically pushing down the weighting units. As the unit is pushed down, more and more data is taken from the figure as opposed to the base model.

This also works with pose figures, as shown here.&#x20;

These weights are used along with the base model to generate a new 3D object. Projected as a hologram&#x20;

This hologram changes in real time as the weighting units are adjusted.

&#x20;These 4 figures were used to generate new concepts for the next OMEN unit. Which we're calling OMEN Prime.&#x20;

When you're happy with the weighting of a figure. It can be locked in by pressing one of the buttons on the front,  you can then change the figure and repeat. The base figure can be changed at any time.&#x20;

This means new characters can be generated with as few as two figures, or as many as you like to get the perfect concept!

Finally. the generation can be fine-tuned using the 'Chaos Slider' and the 'Bias Dial'. these simplify huge numbers of obtuse Ai art functions and changes are shown in real time.&#x20;

\<Time saving visual image.>

The final output of ControlForge is an editable 3D file that can be modified manually and used for the rest of production and development.  &#x20;

### Development

As with all design, it doesn't happen over night. In the case of ControlForge there were a lot of prototypes leading up to it.&#x20;

Our first product, OMEN1, is a healthcare assistant bot that uses Artificial Intelligence diagnose patients from home and cut out a lot of the bloat in the NHS.&#x20;

It can also be seen as an AI that cares.&#x20;

Following on from this, we conceptualised an 'emotional suport 3D printer'. Sounds silly yes, but imagine this. You come home from a long day at work and talk about your woes with your printer. It listens, it learns and it prints you a thingy! I might solve the problem, it might just make you laugh.&#x20;

There was also the 'mild inconvenience logger'. It's a bit of jewellery that listens to all of your daily grumblings about the bins or the council and logs them. Then at the end of the day it designs you a brief that will make your personal world better.&#x20;

Among all of these is the idea of interfacing with artificial intelligence screenlessly.

So Our next concept was Stable Diffusion - in a box. This concept took the basic functions of Image-to-image and gives them a physical interface. Removing the need for a screen from Ai Design.

(Our healthcare robot is called OMEN. We don't do names very well).&#x20;

This idea showed potential and our next concept expanded the number of functions translated into the physical.

&#x20;Most notably giving the user the ability to directly affect the lighting, use physical models in place of images, and introduced the idea of the 'chaos lever'.

As the project was now about screen less interfaces. We experimented with the use of holograms to project the output of the AI generation. Attempting to Incorporate this feature started to narrow down potential forms for the device to take.&#x20;

(Show blender concepts and drawings)&#x20;

## VALIDATION

These concepts were shown to two experts in Human-Computer interaction at the University of Brighton. Dr David Harely and Dr. Sanaz Fallahkhair.

Myself and David talked at length about introducing the element of play and the creative process. And encouraged the idea of allowing users to 'live update' the Ai model as it was being used - similar to ow Stable Diffusion can be fine-tuned with Checkpoint models and LoRA files.&#x20;

\<Show clip>

This went on to inform the final design. Most notably interchanging figures and manual weighting aspect of ControlForge&#x20;



## The Making the Final Product!&#x20;





### Post Product Validation and future applications:

ControlForge is aimed specifically at character design. But when discussing the project with Dr Sanaz, she said that another promising area for this method of AI interaction is cultural heritage and education. Rather than building character. A similar system could be used to rebuild an display artifacts.&#x20;

Heres a few concepts of this idea.&#x20;

## Conclusion

ControlForge is a project founded on the idea that for AI design to truly become a viable part of the workflow. It needs to be given a physical, intuitive interface that offers the designer real-time feedback, and the chance to act upon that feedback.&#x20;

This system gives designers that power. There's no need to write and refine monsterus prompts, adjust unclear and ambiguous settings, then wait for the results to generate.&#x20;

With ControlForge, we believe that products can be conceptualised not only rapidly, but accelerated into the prototyping phase due to the output of a model rather than an image.

As I used to say back in 2023 at university. AI is here, has been for a while. It works exceptionally well and as designers we need to embrace it's power in new ways every day or be left behind like many used to fear  .&#x20;

This is that power.&#x20;

Enjoy the future. &#x20;



